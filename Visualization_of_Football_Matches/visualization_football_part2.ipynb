{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Football Matches using the Lean Startup Method (part 2)\n",
    "\n",
    "This is the second part of the [visualization_football_part1](visualization_football.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"662df752-1580-4c7d-b1b1-d5e21a82a27c\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#662df752-1580-4c7d-b1b1-d5e21a82a27c\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"662df752-1580-4c7d-b1b1-d5e21a82a27c\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '662df752-1580-4c7d-b1b1-d5e21a82a27c' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.2.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#662df752-1580-4c7d-b1b1-d5e21a82a27c\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#662df752-1580-4c7d-b1b1-d5e21a82a27c\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "#Load all libraries\n",
    "import os,sys  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader import reductions\n",
    "from datashader.colors import colormap_select, Hot, inferno\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "from bokeh.palettes import Greens3, Blues3, Blues4, Blues9, Greys9\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "from bokeh.tile_providers import WMTSTileSource, STAMEN_TONER, STAMEN_TERRAIN\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "from utils import country_dict, to_web_marcator, aggregate_dataframe_coordinates\n",
    "\n",
    "output_notebook()\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the map, we can start to improve it. If you are into football, you will notice that there are several points in the north of Spain, that corresponds to Sporting de Gijon. Sadly for Sporting supporters, they have never reached to the Champions. Instead, Sporting Clube de Portugal has participated several times in the championship, but since the current dataset doesn't have teams from Portugal, the system mistakenly thinks that `Sporting CP` from `champions.csv` is the Sporting de Gijon from `stadiums.csv`. So lets fix this issue by getting the stadiums coordinates from the rest of the countries in Europe.  \n",
    "We can get that info from [wikidata](https://query.wikidata.org/). Using `SPARQL` language we can get the information we need:\n",
    "```SQL\n",
    "SELECT ?clubLabel ?venueLabel ?coordinates ?countryLabel  WHERE {\n",
    "  ?club wdt:P31 wd:Q476028.\n",
    "  ?club wdt:P115 ?venue.\n",
    "  ?venue wdt:P625 ?coordinates.\n",
    "  ?club wdt:P17 ?country.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "ORDER BY ?clubLabel\n",
    "```\n",
    "This generates 4435 Results in 10111 ms that can be saved to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stadium_read = pd.read_csv('stadiums_wikidata.csv', usecols=['clubLabel','venueLabel','coordinates','countryLabel'])\n",
    "#df_stadium_read.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to clean the column coordinates. For that we will use a regex pattern. The pattern `[-+]?[0-9]*\\.?[0-9]+` finds any signed float in a string. Then we create two patterns separated by a space and name the columns using this format: `(?P<Longitude>)`. Finally we have to concatente the club information with the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4435\n",
      "Unique team's name number: 4314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Juan Ramón Loubriel Stadium</td>\n",
       "      <td>-66.150833</td>\n",
       "      <td>18.393333</td>\n",
       "      <td>United States of America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Galeshewe Stadium</td>\n",
       "      <td>24.740857</td>\n",
       "      <td>-28.716786</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Real Madrid C</td>\n",
       "      <td>Ciudad Real Madrid</td>\n",
       "      <td>-3.61166667</td>\n",
       "      <td>40.47916667</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>Real Madrid C.F.</td>\n",
       "      <td>Ciudad Real Madrid</td>\n",
       "      <td>-3.61166667</td>\n",
       "      <td>40.47916667</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>Real Madrid FC</td>\n",
       "      <td>Estadio Santiago Bernabéu</td>\n",
       "      <td>-3.68835</td>\n",
       "      <td>40.45306</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Team                      Stadium    Longitude     Latitude  \\\n",
       "3388       Real Madrid  Juan Ramón Loubriel Stadium   -66.150833    18.393333   \n",
       "3389       Real Madrid            Galeshewe Stadium    24.740857   -28.716786   \n",
       "3390     Real Madrid C           Ciudad Real Madrid  -3.61166667  40.47916667   \n",
       "3391  Real Madrid C.F.           Ciudad Real Madrid  -3.61166667  40.47916667   \n",
       "3392    Real Madrid FC    Estadio Santiago Bernabéu     -3.68835     40.45306   \n",
       "\n",
       "                       Country  \n",
       "3388  United States of America  \n",
       "3389              South Africa  \n",
       "3390                     Spain  \n",
       "3391                     Spain  \n",
       "3392                     Spain  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_stadium_read['coordinates'].str.extract('(?P<Longitude>[-+]?[0-9]*\\.?[0-9]+) (?P<Latitude>[-+]?[0-9]*\\.?[0-9]+)', expand=True)\n",
    "df_stadium_new = pd.concat([df_stadium_read['clubLabel'],df_stadium_read['venueLabel'], df_temp, df_stadium_read['countryLabel']], axis=1) \n",
    "df_stadium_new = df_stadium_new.rename(columns = {'clubLabel':'Team', 'venueLabel':'Stadium','countryLabel':'Country'})\n",
    "print(\"Number of rows: %d\" % df_stadium_new.shape[0])\n",
    "unique_teams_stadium = list(set(df_stadium_new['Team']))\n",
    "print(\"Unique team's name number: %d\" % len(unique_teams_stadium))\n",
    "df_stadium_new.take(list(range(3388,3393)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen in the previous dataframe, we came into another problem. The new dataset contains all team instances, all over the world. There are some teams that have the same name in different countries, there is a Real Madrid team from USA and South Africa, and a similar name within a country. In our case, we are only interested in the instance `Real Madrid, Estadio Santiago Bernabeu, -3.68835, 40.45306, Spain`. So how can we find an automated way to filter the correct teams that have participated in the Champions League?\n",
    "\n",
    "A practical approach is to combine an automated and manual way. With the data we have so far we can automatically filter the two first entries using the country. We can get the country info from `champions.csv` dataset. To distinguish teams from the same country we will filter them manually. \n",
    "\n",
    "The first step then is to get a dataframe with all the teams that have participated in Champions and their country of origin. Then we have to remove the repeated entries and rename the country code to the country name that can be found in wikidata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique teams: 502\n"
     ]
    }
   ],
   "source": [
    "df_match = pd.read_csv('champions.csv', usecols=['Date','home','visitor','hcountry','vcountry'])\n",
    "df_match = df_match.rename(columns = {'hcountry':'home_country', 'vcountry':'visitor_country'})\n",
    "df_match_home = df_match[['home','home_country']].rename(columns={'home':'Team','home_country':'Country'})\n",
    "df_match_visitor = df_match[['visitor','visitor_country']].rename(columns={'visitor':'Team','visitor_country':'Country'})\n",
    "df_champions_teams = pd.concat([df_match_home,df_match_visitor], axis=0, ignore_index=True)\n",
    "df_champions_teams = df_champions_teams.drop_duplicates()\n",
    "print(\"Number of unique teams: %d\" % df_champions_teams.shape[0])\n",
    "df_champions_teams['Country'].replace(country_dict, inplace=True)\n",
    "#df_champions_teams.to_csv('match_unique.csv')# To check that the mapping is correct\n",
    "df_champions_teams.sort_values(by='Team',inplace=True)\n",
    "df_champions_teams = df_champions_teams.reset_index(drop=True)\n",
    "#df_champions_teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the list of all teams that have participated in the Champions League, we have to generate a new dataset relating each Champions League matches with the coordinates of the team stadiums. For that we will use the function `similar` to match a the name of the team in the different datasets similarly as we did before. \n",
    "\n",
    "Once the csv has been generated, let's manually erase the combinations that are not correct and save everything in a new file. We won't correct those entries that are not matched, a Data Science project is better out than perfect!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 80 ms, total: 2min 9s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def get_info_similar_team_country(team, country, df_stadium, df, threshold, verbose):\n",
    "    team2 = \"Unknown\"\n",
    "    stadium = \"Unknown\"\n",
    "    latitude = np.NaN\n",
    "    longitude = np.NaN\n",
    "    cols = list(df)\n",
    "    for idx, val in enumerate(df_stadium['Team']):\n",
    "        rank = similar(team, val)\n",
    "        if rank > threshold and country == df_stadium['Country'].iloc[idx]:\n",
    "            if(verbose): print(\"%s and %s(Idx=%d) are %f similar and from the same country %s.\" \n",
    "                               % (team, val, idx, rank, country))\n",
    "            team2 = df_stadium['Team'].iloc[idx]\n",
    "            stadium = df_stadium['Stadium'].iloc[idx]\n",
    "            latitude = df_stadium['Latitude'].iloc[idx]\n",
    "            longitude = df_stadium['Longitude'].iloc[idx]\n",
    "            dtemp = pd.DataFrame([[team, team2, stadium, latitude, longitude, country]], columns=cols)\n",
    "            df = df.append(dtemp, ignore_index=True)\n",
    "    #if there is no match, register it\n",
    "    if(team2 == \"Unknown\"):\n",
    "        df_nomatch = pd.DataFrame([[team, team2, stadium, latitude, longitude, country]], columns=cols)\n",
    "        df = df.append(df_nomatch, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def generate_new_stadium_dataset(df_champions_teams, df_stadium_new, threshold=0.6, verbose=False):\n",
    "    df = pd.DataFrame(columns=['Team', 'Team2', 'Stadium', 'Latitude','Longitude','Country'])\n",
    "    for idx, row in df_champions_teams.iterrows():\n",
    "        df = get_info_similar_team_country(row['Team'],row['Country'], df_stadium_new, df, \n",
    "                                           threshold=threshold, verbose=verbose)\n",
    "    return df\n",
    "\n",
    "verbose = False # You can change this to True to see all the combinations\n",
    "threshold = 0.5\n",
    "df_stadiums_champions = generate_new_stadium_dataset(df_champions_teams, df_stadium_new, threshold, verbose)\n",
    "df_stadiums_champions.to_csv('stadiums_champions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we filtered the entries in the csv, let's load again the data and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stadiums_champions = pd.read_csv('stadiums_champions_filtered.csv', usecols=['Team','Stadium','Latitude','Longitude','Country'])\n",
    "#df_stadiums_champions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in part 1, let's create a dataframe that relates each match with the coordinates of its stadium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches with complete data: 5110 out of 6554\n",
      "CPU times: user 5min 24s, sys: 268 ms, total: 5min 24s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_info_similar_team(team, df_stadium, threshold=0.6, verbose=False):\n",
    "    max_rank = 0\n",
    "    max_idx = -1\n",
    "    stadium = \"Unknown\"\n",
    "    latitude = np.NaN\n",
    "    longitude = np.NaN\n",
    "    for idx, val in enumerate(df_stadium['Team']):\n",
    "        rank = similar(team, val)\n",
    "        if rank > threshold:\n",
    "            if(verbose): print(\"%s and %s(Idx=%d) are %f similar.\" % (team, val, idx, rank))\n",
    "            if rank > max_rank:\n",
    "                if(verbose): print(\"New maximum rank: %f\" %rank)\n",
    "                max_rank = rank\n",
    "                max_idx = idx\n",
    "                stadium = df_stadium['Stadium'].iloc[max_idx]\n",
    "                latitude = df_stadium['Latitude'].iloc[max_idx]\n",
    "                longitude = df_stadium['Longitude'].iloc[max_idx]\n",
    "    return stadium, latitude, longitude\n",
    "\n",
    "df_match_stadium_new= df_match\n",
    "home_stadium_index = df_match_stadium_new['home'].map(lambda x: get_info_similar_team(x, df_stadiums_champions))\n",
    "visitor_stadium_index = df_match_stadium_new['visitor'].map(lambda x: get_info_similar_team(x, df_stadiums_champions))\n",
    "df_home = pd.DataFrame(home_stadium_index.tolist(), columns=['home_stadium', 'home_latitude', 'home_longitude'])\n",
    "df_visitor = pd.DataFrame(visitor_stadium_index.tolist(), columns=['visitor_stadium', 'visitor_latitude', 'visitor_longitude'])\n",
    "df_match_stadium_new = pd.concat([df_match_stadium_new, df_home, df_visitor], axis=1, ignore_index=False)\n",
    "df1 = df_match_stadium_new['home_stadium'] == 'Unknown'\n",
    "df2 = df_match_stadium_new['visitor_stadium'] == 'Unknown'\n",
    "n_complete_matches = df_match_stadium_new.shape[0] - df_match_stadium_new[df1 | df2].shape[0]\n",
    "print(\"Number of matches with complete data: %d out of %d\" % (n_complete_matches, df_match_stadium_new.shape[0]))\n",
    "df_match_stadium_new.take([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to aggregate the coordinates and transform them to mercator format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg = aggregate_dataframe_coordinates(df_match_stadium_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15330\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.019774e+06</td>\n",
       "      <td>4.687522e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.277504e+06</td>\n",
       "      <td>5.588304e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.821102e+05</td>\n",
       "      <td>5.808884e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.105852e+05</td>\n",
       "      <td>4.932000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude     Longitude\n",
       "0 -1.019774e+06  4.687522e+06\n",
       "1  2.277504e+06  5.588304e+06\n",
       "2           NaN           NaN\n",
       "3  6.821102e+05  5.808884e+06\n",
       "4 -4.105852e+05  4.932000e+06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_mercator = df_agg.apply(lambda row: to_web_mercator(row['Latitude'], row['Longitude']), axis=1)\n",
    "print(\"Number of rows: %d\" % df_agg_mercator.shape[0])\n",
    "df_agg_mercator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to plot the trayectories in the map using datashader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_width  = 850\n",
    "plot_height = 600\n",
    "x_range = (-1.9e6, 5.9e6)\n",
    "y_range = (3.7e6, 9.0e6)\n",
    "def create_image(x_range=x_range, y_range=y_range, w=plot_width, h=plot_height):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.line(df_agg_mercator, 'Latitude', 'Longitude',  ds.count())\n",
    "    #img = tf.shade(agg, cmap=reversed(Blues3), how='eq_hist')\n",
    "    img = tf.shade(agg, cmap=inferno, how='eq_hist')\n",
    "    return img\n",
    "\n",
    "def base_plot(tools='pan,wheel_zoom,reset',plot_width=plot_width, plot_height=plot_height,**plot_args):\n",
    "    p = figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n",
    "        x_range=x_range, y_range=y_range, outline_line_color=None,\n",
    "        min_border=0, min_border_left=0, min_border_right=0,\n",
    "        min_border_top=0, min_border_bottom=0, **plot_args)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bokeh.models.renderers.TileRenderer at 0x7f5c18474ac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArcGIS=WMTSTileSource(url='http://server.arcgisonline.com/ArcGIS/rest/services/World_Street_Map/MapServer/tile/{Z}/{Y}/{X}.png')\n",
    "p = base_plot()\n",
    "p.add_tile(ArcGIS)\n",
    "#InteractiveImage(p, create_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the image for github\n",
    "<p align=\"center\">\n",
    "<img src=\"map2.JPG\" alt=\"Matches between teams in the Champions League\" width=\"60%\"/>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
